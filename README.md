# Parellel Computing Technology
Project focuses on developing and analyzing parallel algorithms for matrix multiplication, utilizing MPI (Message Passing Interface) to explore various parallel computing concepts and techniques.
____

### Lab Highlights
- **[Lab 1](https://github.com/MilaHalko/S6_ParallelComputingTechnology/tree/Lab1/Lab1):**
  Introduction to basic MPI operations, setup, and a simple communication example.
  <img src="/images/lab1.png" width="400" align='left' >
  <br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>
  
- **[Lab 2](https://github.com/MilaHalko/S6_ParallelComputingTechnology/tree/Lab2/MatrixMultiplier):**
  Implementation and efficiency analysis of parallel matrix multiplication algorithms using direct one-to-one MPI communication methods. <br>
  <img src="/images/lab2.png" width="500" align='left'>
  <br><br><br><br><br><br><br><br><br><br><br><br>
  
- **[Lab 3](https://github.com/MilaHalko/S6_ParallelComputingTechnology/tree/Lab3/SyncMethods):**
  Introduction to synchronization mechanisms in parallel programming, focusing on mutexes and locks. <br>
  <img src="/images/lab3.png" width="300" align='left' />
  <br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>
  
- **[Lab 4](https://github.com/MilaHalko/S6_ParallelComputingTechnology/tree/Lab4/WordsCounter),
    [Lab 6](https://github.com/MilaHalko/S6_ParallelComputingTechnology/tree/Lab6/Lab6/src),
    [Lab 7](https://github.com/MilaHalko/S6_ParallelComputingTechnology/tree/Lab7/Lab7/src):**
  Advanced usage of MPI for matrix multiplication, covering different aspects of MPI communications such as one-to-many, many-to-one, and collective communication patterns. <br>
  <img src="/images/lab5.png" width="500" align='left' />
  <img src="/images/lab6.png" width="400" align='left' />
  <img src="/images/lab7.png" width="500" align='left' />
  <br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>
____

### Key Features
- **Parallel Matrix Multiplication:** Implementation of matrix multiplication using MPI to demonstrate the effectiveness of parallel computation.
- **MPI Communication Patterns:** Explores various MPI communication methods, including blocking and non-blocking communications and their impact on performance.
- **Performance Analysis:** Detailed analysis of different parallel algorithms' performance, examining how factors such as matrix size and the number of processors affect the computational speed and efficiency.
